# Основы многопоточности в .NET

Главу о многопоточности стоит начать с мыслей о том, что вся многопоточность в вопросах потоков и блокировок .NET основана на функционале операционной системы. Это значит, что в .NET нет никаких своих, тонких потоков. Зато есть обёртки над потоками операционной системы и над блокировками, которые также корнями уходят в операционную систему.

В общем потому-то и необходимо начинать изучение многопоточности с уровня операционной системы, иначе нет никакого реального представления об алгоритмах работы потоков. Для обычного, разаботчика в сфере .NET потоки -- это скорее неясная абстракция чем что-то понятное. А потому -- нет понимания, что такое блокировка. Что такое синхронизация уровня ядра и чем она отличается от синхронизации пользовательского уровня.

А потому если вы начали с этой главы, вернитесь, пожалуйста, назад. В предудущих главах описаны очень важные вещи, которые выведут ваши знания на новый уровень (а вместе с ними -- и уровень оплаты труда).

Что такое поток? Проговорим ещё раз. Это некая последовательность команд для процессора, которые он исполняет единым *потоком* параллельно либо псевдопараллельно относительно других *потоков* исполнения кода. Параллельно -- потому что код разных потоков может исполняться на разных физических ядрах. Псевдопараллельно -- потому что код разных потоков может исполняться на одном физическом ядре. А потому -- чтобы эмулировать параллельность в глазах у пользователя они бьются по времени исполнения на очень короткие интервалы и чередутся, создавая иллюзию параллельного исполнения: это можно сравнить с цветной печатью. Если посмотреть на полноцветную печать под лупой (или при помощи камеры смартфона), можно заметить микроточки CMYK (Cyan, Magneta, Yellow, Key). Их можно увидеть только при увеличении, но на расстоянии они образуют единое пятно итогового цвета.

Добиться того, чтобы завладеть ядром процессора монопольно в .NET нет возможности. Да и в ОС нет такого функционала. А это значит, что любой ваш поток будет прерван в абсолютно любом месте: даже по середине операции `a = b;`, когда `b` считали, а `a` ещё не записана просто потому, что помимо вас на том же ярде работает ещё кто-то. И с очень высокой долей вероятности прерваны вы будете на более длительный срок нежели вам отпущено на работу: при большом количестве активных потоков в системе помимо вас на ядре их будет несколько. А значит вы будете по чуть-чуть исполняться в порядке некоторой очереди. Сначала вы, потом все остальные и только потом -- снова вы.

Однако, создание потока -- это очень дорогая операция. Ведь что такое "создать поток"? Для начала это обращение в операционную систему. Обращение в операционную систему -- это преодоление барьера между слоем прикладного ПО и слоем операционной системы. Слои эти обеспечиваются процессором, а стороны барьеров - *кольцами защиты*. Прикладное программное обеспечение имеет кольцо защиты `Ring 3`, тогда как уровень ОС занимает кольцо `Ring 0`. Вызов методов из кольца в кольцо -- операция дорогая, а перехода между тем два: из `Ring 3` в `Ring 0` и обратно. Плюс создание стеков потока: один для `Ring 3`, второй -- для `Ring 0`. Плюс создание дополнительных структур данных со стороны .NET. В общем чтобы что-то исполнить параллельно чему-то *быстро*, для начала придётся потратить много времени. 

Однако люди заметили, что долгих операций, которые бы исполнялись непрерывно, не уходя в ожидание оборудования, мало. Скорее это выглядит так:
1. *Ожидание сети по вопросу подключения клиента*
2. Проанализировали запрос, сформировали запрос к БД, отправили
3. *Ожидание ответа от сервера БД*
4. Ответ получен, перевели в ответ от сервиса
5. *Отправили ответ*

И пункты (2) и (4) -- не так долго выполняются. Скорее это -- очень короткие по времени исполнения участки кода. А потому стоит задаться вопросом: для чего под них создавать отдельные потоки (тут отсылка к неверному многими трактовании слова *асинхронно* и повсеместной попытки что-то отработать параллельно)? В конце концов цепочка (1) - (5) работает целиком последовательно, а это значит, что в точках (1), (3) и (5) поток исполнения находится в блокировке ожидания оборудования, т.к. ждёт ответа от сетевой карты. Т.е. не участвует в планировании операционной системой и никак не влияет на её производительность. Тогда что, web-серверу надо создать поток под всю цепочку? А если сервер обрабатывает 1000 подключений в секунду? Мы же помним, что один поток создаётся крайне долго. Значит он не сможет работать с такими скоростями если будет создавать под каждый запрос поток. Работать на уже существующих? *Брать потоки в аренду?*

Именно поэтому и возник пул потоков, ThreadPool. Он решает несколько задач:
- с одной стороны он абстрагирует создание потока: мы этим заниматься не должны
- создав когда-то поток, он исполняет на нём совершенно разные задачи. Вам же не важно, на каком из них исполняться? Главное чтобы был;
- а потому мы более не тратим время на создание потока ОС: мы работаем на уже созданных
- а потому мы нагружая ThreadPool своими делегатами мы можем равномерно загрузить ядра CPU работой

Однако, как мы убедимся позже у любой такой абстракции есть масса нюансов, в которых эта абстракция работает очень плохо и может стать причиной серъёзных проблем. Пул потоков можно использовать не во всех сценариях, а во многих он станет серьёзным "замедлителем" процессов. Но.. обо всём по порядку.

## Работа ThreadPool

Данная глава - вводная и здесь будут даны знания "базового слоя". Т.е. без особых подробностей, но чтобы вы могли понять суть. Все подробности будут даны дальше: при дальнейшем рассмотрении.

Работает пул потоков крайне просто. Существует очередь делегатов, которые переданы пулу потоков на исполнение. Очередь делегатов хранится в широко-известной коллекции `ConcurrentQueue`. Далее, когда вы вызываете `ThreadPool.QueueUserWorkItem(() => Console.WriteLine($"Hello from {Thread.CurrentThread.ManagedThreadId}"))`, то просто помещаете делегат в эту очередь. 

ThreadPool внутри себя в зависимости от некоторых метрик, о которых мы поговорим позже создаёт некоторое необходимое ему количество рабочих потоков. Каждый из которых содержит цикл выборки делегатов на исполнение: и запускает их. Если упрощать, внутренний код выглядит примерно так:

```csharp
void ThreadMethod()
{

    // ...
    while(needToRun)
    {
        if(_queue.TryDequeue(out var action))
        {
            action();
        }
    }
    // ...
```

Конечно же он сложнее, но общая суть именно такая.

Однако помимо кода, который исполняет процессор (т.н. IO-bound код) существует также код, приодящий к блокировке исполнения потока: ожиданию ответа от оборудования. Клавиатура, мышь, сеть, диск, вертикальная синхронизация монитора и прочие сигналы от оборудования. Этот код называется IO-bound. Если мы будем ожидать оборудование на потоках пула, это приведёт к росту потоков внутри пула как минимум и как максимум это приведёт к тому, что сам пул начнёт работать сильно медленнее. Пока он поймёт, что ему необходимо расширение, пройдёт много времени. У него появится некий "лаг" между наваливанием нагрузки на пул и срабатыванием кода, расширяющего пул.

Чтобы такого избежать, ввели второй пул потоков. Для IO-bound операций. А потому в стандартном ThreaPool два пула: один -- для CPU-bound операций и второй -- для IO-bound.

Для нас это значит, что в делегате, работающем в ThreadPool вставать в блокировку нельзя. Он для этого не предназначен. Вместо этого необходимо следующий код:

```csharp
ThreadPool.RegisterWaitForSingleObject(
    waitObject,    // объект ожидания
    (state) => Console.WriteLine($"Hello from {Thread.CurrentThread.ManagedThreadId}"),
    null,          // объект состояния для передачи в делегат (state)
    0,             // timeout ожидания объекта состояния (0 = бесконечно)
    true);         // ждать ли ещё раз при срабатывании waitObject (например, если waitObject == AutoResetEvent)
```

## SynchronizationContext
