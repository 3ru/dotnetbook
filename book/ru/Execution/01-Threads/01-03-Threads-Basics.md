# Основы многопоточности в .NET

Главу о многопоточности стоит начать с мыслей о том, что вся многопоточность в вопросах потоков и блокировок .NET основана на функционале операционной системы. Это значит, что в .NET нет никаких своих, тонких потоков. Зато есть обёртки над потоками операционной системы и над блокировками, которые также корнями уходят в операционную систему.

В общем потому-то и необходимо начинать изучение многопоточности с уровня операционной системы, иначе нет никакого реального представления об алгоритмах работы потоков. Для обычного, разаботчика в сфере .NET потоки -- это скорее неясная абстракция чем что-то понятное. А потому -- нет понимания, что такое блокировка. Что такое синхронизация уровня ядра и чем она отличается от синхронизации пользовательского уровня.

А потому если вы начали с этой главы, вернитесь, пожалуйста, назад. В предудущих главах описаны очень важные вещи, которые выведут ваши знания на новый уровень (а вместе с ними -- и уровень оплаты труда).

## Thread

Что такое поток? Проговорим ещё раз. Это некая последовательность команд для процессора, которые он исполняет единым *потоком* параллельно либо псевдопараллельно относительно других *потоков* исполнения кода. Параллельно -- потому что код разных потоков может исполняться на разных физических ядрах. Псевдопараллельно -- потому что код разных потоков может исполняться на одном физическом ядре. А потому -- чтобы эмулировать параллельность в глазах у пользователя они бьются по времени исполнения на очень короткие интервалы и чередутся, создавая иллюзию параллельного исполнения: это можно сравнить с цветной печатью. Если посмотреть на полноцветную печать под лупой (или при помощи камеры смартфона), можно заметить микроточки CMYK (Cyan, Magneta, Yellow, Key). Их можно увидеть только при увеличении, но на расстоянии они образуют единое пятно итогового цвета.

Добиться того, чтобы завладеть ядром процессора монопольно в .NET нет возможности. Да и в ОС нет такого функционала. А это значит, что любой ваш поток будет прерван в абсолютно любом месте: даже по середине операции `a = b;`, когда `b` считали, а `a` ещё не записана просто потому, что помимо вас на том же ярде работает ещё кто-то. И с очень высокой долей вероятности прерваны вы будете на более длительный срок нежели вам отпущено на работу: при большом количестве активных потоков в системе помимо вас на ядре их будет несколько. А значит вы будете по чуть-чуть исполняться в порядке некоторой очереди. Сначала вы, потом все остальные и только потом -- снова вы.

Однако, создание потока -- это очень дорогая операция. Ведь что такое "создать поток"? Для начала это обращение в операционную систему. Обращение в операционную систему -- это преодоление барьера между слоем прикладного ПО и слоем операционной системы. Слои эти обеспечиваются процессором, а стороны барьеров - *кольцами защиты*. Прикладное программное обеспечение имеет кольцо защиты `Ring 3`, тогда как уровень ОС занимает кольцо `Ring 0`. Вызов методов из кольца в кольцо -- операция дорогая, а перехода между тем два: из `Ring 3` в `Ring 0` и обратно. Плюс создание стеков потока: один для `Ring 3`, второй -- для `Ring 0`. Плюс создание дополнительных структур данных со стороны .NET. В общем чтобы что-то исполнить параллельно чему-то *быстро*, для начала придётся потратить много времени. 

Однако люди заметили, что долгих операций, которые бы исполнялись непрерывно, не уходя в ожидание оборудования, мало. Скорее это выглядит так:
1. *Ожидание сети по вопросу подключения клиента*
2. Проанализировали запрос, сформировали запрос к БД, отправили
3. *Ожидание ответа от сервера БД*
4. Ответ получен, перевели в ответ от сервиса
5. *Отправили ответ*

И пункты (2) и (4) -- не так долго выполняются. Скорее это -- очень короткие по времени исполнения участки кода. А потому стоит задаться вопросом: для чего под них создавать отдельные потоки (тут отсылка к неверному многими трактовании слова *асинхронно* и повсеместной попытки что-то отработать параллельно)? В конце концов цепочка (1) - (5) работает целиком последовательно, а это значит, что в точках (1), (3) и (5) поток исполнения находится в блокировке ожидания оборудования, т.к. ждёт ответа от сетевой карты. Т.е. не участвует в планировании операционной системой и никак не влияет на её производительность. Тогда что, web-серверу надо создать поток под всю цепочку? А если сервер обрабатывает 1000 подключений в секунду? Мы же помним, что один поток создаётся крайне долго. Значит он не сможет работать с такими скоростями если будет создавать под каждый запрос поток. Работать на уже существующих? *Брать потоки в аренду?*

## ThreadPool

Именно поэтому и возник пул потоков, ThreadPool. Он решает несколько задач:
- с одной стороны он абстрагирует создание потока: мы этим заниматься не должны
- создав когда-то поток, он исполняет на нём совершенно разные задачи. Вам же не важно, на каком из них исполняться? Главное чтобы был;
- а потому мы более не тратим время на создание потока ОС: мы работаем на уже созданных
- а потому мы нагружая ThreadPool своими делегатами мы можем равномерно загрузить ядра CPU работой

Однако, как мы убедимся позже у любой такой абстракции есть масса нюансов, в которых эта абстракция работает очень плохо и может стать причиной серъёзных проблем. Пул потоков можно использовать не во всех сценариях, а во многих он станет серьёзным "замедлителем" процессов. Но.. обо всём по порядку.

Данная глава - вводная и здесь будут даны знания "базового слоя". Т.е. без особых подробностей, но чтобы вы могли понять суть. Все подробности будут даны дальше: при дальнейшем рассмотрении.

Работает пул потоков крайне просто. Существует очередь делегатов, которые переданы пулу потоков на исполнение. Очередь делегатов хранится в широко-известной коллекции `ConcurrentQueue`. Далее, когда вы вызываете `ThreadPool.QueueUserWorkItem(() => Console.WriteLine($"Hello from {Thread.CurrentThread.ManagedThreadId}"))`, то просто помещаете делегат в эту очередь. 

ThreadPool внутри себя в зависимости от некоторых метрик, о которых мы поговорим позже создаёт некоторое необходимое ему количество рабочих потоков. Каждый из которых содержит цикл выборки делегатов на исполнение: и запускает их. Если упрощать, внутренний код выглядит примерно так:

```csharp
void ThreadMethod()
{

    // ...
    while(needToRun)
    {
        if(_queue.TryDequeue(out var action))
        {
            action();
        }
    }
    // ...
```

Конечно же он сложнее, но общая суть именно такая.

Однако помимо кода, который исполняет процессор (т.н. IO-bound код) существует также код, приводящий к блокировке исполнения потока: ожиданию ответа от оборудования. Клавиатура, мышь, сеть, диск, вертикальная синхронизация монитора и прочие сигналы от оборудования. Этот код называется IO-bound. Если мы будем ожидать оборудование на потоках пула, это приведёт к тому, что часть потоков в пуле перестенут быть рабочими на время блокировки. Это как минимум испортит пулу потоков статистики которые он считает и как следствие этого пул начнёт работать сильно медленнее. Пока он поймёт, что ему необходимо расширение, пройдёт много времени. У него появится некий "лаг" между наваливанием нагрузки на пул и срабатыванием кода, расширяющего его. А без блокировок-то он отрабатывал бы очень быстро.

Чтобы избежать таких ситуаций и сохранить возможность "аренды" потоков, ввели второй пул потоков. Для IO-bound операций. А потому в стандартном ThreadPool два пула: один -- для CPU-bound операций и второй -- для IO-bound.

Для нас это значит, что в делегате, работающем в ThreadPool вставать блокировку нельзя. Он для этого не предназначен. Вместо этого необходимо использовать следующий код:

{.wide}
```csharp
ThreadPool.QueueuserWorkItem(
    _ => {

        // ... 1

        // 2
        ThreadPool.RegisterWaitForSingleObject(
            waitObject,    // объект ожидания
            (state) => Console.WriteLine($"Hello from {Thread.CurrentThread.ManagedThreadId}"),  // 3
            null,          // объект состояния для передачи в делегат (state)
            0,             // timeout ожидания объекта состояния (0 = бесконечно)
            true);         // ждать ли ещё раз при срабатывании waitObject 
                           // (например, если waitObject == AutoResetEvent)

        // ... 4

    }, null);
);
```

[>]: Тут конечно же стоит помнить о том, что код, который сработает *после* RegisterWaitForSingleObject отработает в лучшем случае параллельно с делегатом, переданным в RegisterWaitForSingleObject, а более вероятно - первее делегата, но в любом случае -- в другом потоке. (1), (2), (3), (4) не будут вызваны последовательно. Последовательно будут вызваны только (1), (2) и (4). А (3) - либо параллельно с (4) либо после. 

В этом случае второй делегат уйдёт на второй пул IO-bound операций, который не влияет на исполнение CPU-bound пула потоков.

## SynchronizationContext

ThreadPool -- вещь удобная и во многом всем понятная, т.к. очень простая. Однако, было бы ещё удобнее если бы можно было ввести ещё более абстрактное понятие, которое бы означало, что я хочу синхронно или же асинхронно выполнить некий код относительно своего. Зачем? Ну потому что у нас потоки бывают не только у ThreadPool, но которые обладают его свойствами. А механику было бы хорошо иметь общую: чтобы алгоритмы, рассчитанные на то, чтобы работать частично асинхронно не задумывались бы над тем, как это сделать. Простой пример идеальной абитракции -- `IEnumerable<T>`. Его может реализовать кто угодно и как угодно. Однако передав это нечто в метод, принимающий `IEnumerable`, вы даёте доступ к этому чему-то как к перечислению неких элементов.

Точно также и в случае абстрагирования группы потоков, существует абстракция "контекст синхронизации", через которую пользовательский код может запланировать исполнение некоторого делегата синхронно либо асинхронно со своим:

```csharp
public class SynchronizationContext
{
  void Post(..); // (асинхронно)

  void Send(..); // (синхронно)
}
```

Этот контекст синхронизации может скрывать под собой что угодно: и ThreadPool, и любой другой пул потоков и даже всего-навсего один поток. Однако стоит упомянуть, что есть контекст синхронизации по-умолчанию и доступ к нему, к сожалению, сделан не очень удачно. Для этого необходимо вызвать:

```csharp
var ctx = new SynchronizationContext();
```

хотя было бы намного логичнее если бы API был бы таким:

```csharp
var ctx = SynchronizationContext.Default;
// или даже так:
var ctx = ThreadPool.SynchronizationContext;
```

Последнее вообще бы внесло много ясности в то, что SynchronizationContext вообще есть и для чего он нужен.

### Примеры

Хорошими примерами контекстов синхронизации, отличных от обёрток вокруг ThreadPool могут послужить обёртки вокруг UI потоков в WinForms и WPF.

Как известно, код WPF и WinForms исполняется в рамках одного-единственного UI потока. Связано это со многими причинами, но одна из них - это цикл выработки сообщений от Windows. Для этого цикла создаётся новый поток (либо используется основной поток приложения) и рамках этого потока создаётся бесконечный цикл выборки сообщений от Windows: нажали на клавишу, подвигали мышкой, drag-n-drop и прочие. Туда же через контекст синхронизации UI потока можно отдать некоторые делегаты на исполнение и тогда при очередном витке цикла выборки сообщений делегат будет выбран из очереди и исполнен в потоке UI.

Однако для некоторого алгоритма:

```csharp
public void DoSomethig(int x, int y, SynchronizationContext ctx = default)
{
    ((ctx ?? SynchronizationContext.Current) ?? new SynchronizationContext())
        .Post(() => x + y);
}
```
Решение будет следующим:
- Если передан SynchronizationContext, использовать его;
- Иначе Использовать текущий;
- Если текущий не задан -- использовать контекст по-умлочанию.

И в рамках этого контекста вызвать код сложения двух чисел:
- если этот код вызвать, передав ему контекст синхронизации UI, то сложение двух чисел произойдёт в потоке UI;
- если ничего не передавать, то будет выбран текущий;
- если текущий не установлен, будет выбран контекст по-умолчанию (API его выбора очень кривое).