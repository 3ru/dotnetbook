# Практика отпимизаций по работе с памятью

В своей практике оптимизаций я сделал интересный, хотя и логичный вывод. Если мы избавлемся от срабатываний GC, приложение работает быстрее. Звучит как: "ну естествено! Кто бы спорил-то?". Однако, далеко не каждый ответит на вопрос: "на сколько"? 

Мой пример, конечно же, будет несколько наивен.. Но когда я работал над протоколом Samba и мной была переписана библиотека `SMBLibrary`, то результат при той же структуре кода, но другими способами по работе с памятью составил `-41%` к времени исполнения. Вдумайтесь: `41%` на аллокацию, GC и неоптимальный выбор структур данных.

Конечно же, основная масса времени уходила на работу со структурами данных типа `Dictionary`, `List`, `Queue`, т.к. заполнение шло без выставленного `capacity`, однако и на траффик мелких объектов уходило много времени.

Траффик объектов приводит, как мы помним, к GC0. Однако если траффик реально плотный, то приложение попросту не успеет освободить ссылки и объекты вместо ухода на покой в GC0 сделают это в GC1. К чему это приведет? К тому, что GC будет работать дольше. Т.е. ему придется переработать большой участок памяти для понимания, на какие объекты более нет ссылок. Плюс к этому, если на эти обекты будут ссылаться какие-то старые коллекции или старые объекты (из мира второго поколения), то в игру вступает таблица карт (подробнее о которой вы можете прочитать в труде Конрада Кососы .NET Memory Management). Что включает еще большие расходы на анализ. Звучит как-то не очень оптимально. Что же делать? Попахивает безнадёгой: сущность-то всё равно надо выделить. Причем не структуру, а именно класс. И память при этом лупит по полной. Однако, если вспомнить главу "Время жизни сущностей", то мы вспомним, что по сути время жизни любой сущности -- это несколько выртуальное понятие и скорее зависит от восприятия *человека*. Именно человека. Ведь по факту никакого выделения памяти не существует. Есть разметка памяти под тип (одон поле) и понимание программным кодом, что *вот с вот этого* момента объектом можно пользоваться. 

А потому мы легко можем сделать еще один слой виртуализации понятия времени жизни сущности. Например, так: 

```csharp
var instance = Heap<Foo>.Create();
Heap<Foo>.Return(instance)
```

Что произошло с нашим восприятием? Ассоциативным мышлением. Если раньше мы вызывали `new Foo()`, что для *нас* означало "создать *из ниоткуда* объект типа Foo", то теперь при вызове `Heap<Foo>.Create()` возникает новый конструкт: "создать объект в куче объектов типа Foo". И "вернуть объект типа Foo обратно в кучу". 

Согласитесь, интересно? Код программы может быть каким угодно. *Мы* наделяем его смыслом. Таким, каким хотим чтобы он воспринимался *правильно*. Ведь если назвать всё тоже самое по-другому:

```csharp
var instance = FreeObjectsQueue<Foo>.Dequeue();
FreeObjectsQueue<Foo>.Enqueue(instance)
```

Мы перестанем воспринимать это как кучу. Просто какая-то обёрнутая очередь. А если так:  

```csharp
var instance = UnfocusedObjects<Foo>.MakeFocus();
UnfocusedObjects<Foo>.RemoveFocus(instance)
```

То несмотря на то, что это -- совершенно то же самое с точки зрения функционала, пользоваться этим мы не станем.

Однако, вернёмся к нашему примеру, которым пользоваться хочется:

```csharp
var instance = Heap<Foo>.Create();
Heap<Foo>.Return(instance)
```

И подумаем, как мы можем его реализовать. На самом деле, когда я впервые написал эту реализацию, пришли даже некоторые сомнения, что я вообще имею право вот **это** называть Heap'ом:

```csharp
public static class Heap<T> where T : class, new()
{
    private ConcurrentQueue<T> objects;
    private const MinPoolSize = 32;

    static Heap()
    {
        objects = new ConcurrentQueue<T>(MinPoolSize);
    }

    public static T Create()
    {
        if(objects.TryDeqeue(out var instance))
        {
            return instance;
        }
        return new T();
    }

    public static void Return(T instance) => objects.Enqeue(instance);
}
```

Он очень прост: даже примитивен. Тут нет ни массива, ни его разметки на объекты... Нет тут и списка свободных участков, разделенных на секции исходя из размера... Тут ничего нет. Просто очередь. Станислав?? Вы это... Главу ради очереди пишете что-ли? *Бегающие глаза*. Ну в общем-то в каком-то смысле да. Вообще стек работает быстрее. А ещё быстрее с некоторыми хитростями. Но.. подождите закрывать главу! Скоро вы всё поймёте и полюбите этот небольшой набор строк. 

Изменилось ли ваше отношение к конструкции `var instance = Heap<Foo>.Create()`? Стало ли оно "ну и примитивно же"? А ведь напрасно! Всё, что мы тут видим -- это менеджмент объектов одного типа. Список занятых участков нам хранить нет смысла: объекты у пользователя. Зато мы имеем целый ряд преимуществ:

- Мы получим объект в любом случае: даже если объектов в пуле нет вообще;
- Если объекты в пуле есть, мы получим их: переиспользуем;
- Мы можем предварительно создать множество объектов и поместить их в пул рядом чтобы они:
  - легли плотно во втором поколении;
  - легли плотно, помещаясь всей группой в L1 кэше;
- Если вдруг... по какой-то причине мы не вернули объект в пул.. Ничего страшного: его соберёт GC. А такие утечки легко отследить в `dotMemory`.

А исходя из последнего пункта можно сделать вывод, что переход на `Heap<T>.Create()` обойдётся достаточно легко: можно сначала вмето `new T()` везде написать `Heap<T>.Create()`, после чего первым шагом написать `Heap<T>.Return(instance)` там, где вы считаете, что это необходимо. А дальше -- запустить `dotMemory` и проверить наличие "утечек": траффика объектов вашего типа. Вот и всё.

[>]: Вот тоже забавное заблюдение. Слово "утечка" теперь будет значить не только незапланированное удержание некоторого объекта в памяти, но и незапланированный уход объекта в Garbage Collector.

